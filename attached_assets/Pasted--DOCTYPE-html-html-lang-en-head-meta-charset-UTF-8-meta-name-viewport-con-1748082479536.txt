<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Liquid Learning Lab - Voice AI Tutor (Dark Mode)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            scroll-behavior: smooth;
            overflow: hidden; /* Prevent body scroll, main handles it */
            background-color: #1a202c; /* dark gray */
            color: #e2e8f0; /* light gray text */
        }
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');

        /* Dark Mode Specifics */
        .bg-dark-card { background-color: #2d3748; } /* dark slate */
        .border-dark-subtle { border-color: #4a5568; } /* darker slate */
        .text-dark-primary { color: #e2e8f0; }
        .text-dark-secondary { color: #a0aec0; }
        .text-indigo-accent { color: #818cf8; } /* Brighter indigo for dark mode */
        .text-green-accent { color: #48bb78; } /* Brighter green for dark mode */
        .text-purple-accent { color: #a78bfa; } /* Brighter purple for dark mode */

        /* Conversation Bubble Styling */
        .chat-bubble {
            max-width: 80%;
            padding: 10px 15px;
            border-radius: 20px;
            margin-bottom: 10px;
            word-wrap: break-word;
        }
        .user-bubble {
            background-color: #4338ca; /* dark blue-indigo */
            align-self: flex-end;
            border-bottom-right-radius: 5px;
            color: #e0f2fe;
        }
        .ai-bubble {
            background-color: #5b21b6; /* dark purple-indigo */
            align-self: flex-start;
            border-bottom-left-radius: 5px;
            color: #ede9fe;
        }
        
        /* Loading spinner */
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-left-color: #818cf8; /* indigo-400 */
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* SVG Icon Animations */
        @keyframes rotate-y {
            0% { transform: rotateY(0deg); }
            100% { transform: rotateY(360deg); }
        }
        @keyframes pulse-fill {
            0%, 100% { fill: currentColor; }
            50% { fill: #a78bfa; }
        }
        @keyframes microphone-pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.1); opacity: 0.7; }
        }
        .icon-animate-rotate { animation: rotate-y 4s infinite linear; }
        .icon-animate-pulse-fill { animation: pulse-fill 2s infinite ease-in-out; }
        .microphone-active { animation: microphone-pulse 1s infinite alternate; }

        /* Side Menu Transition */
        .sidebar {
            transition: transform 0.3s ease-in-out;
        }
        .sidebar-hidden {
            transform: translateX(-100%);
        }
        .sidebar-visible {
            transform: translateX(0);
        }
        @media (min-width: 768px) { /* md breakpoint */
            .sidebar {
                transform: translateX(0) !important; /* Always visible on desktop */
            }
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100">

    <header class="bg-gray-800 text-gray-100 p-4 shadow-lg flex justify-between items-center z-40 relative">
        <div class="flex items-center">
            <button id="menu-toggle" class="md:hidden p-2 mr-3 rounded-md hover:bg-gray-700 focus:outline-none focus:ring-2 focus:ring-indigo-500">
                <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg>
            </button>
            <h1 class="text-2xl font-bold">Liquid Learning Lab: AI Tutor</h1>
        </div>
        <button id="settings-button-header" class="bg-indigo-600 hover:bg-indigo-700 px-4 py-2 rounded-md text-sm font-semibold transition-colors flex items-center">
            <svg class="w-5 h-5 mr-2" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"/></svg>
            Settings
        </button>
    </header>

    <main class="flex flex-1 h-[calc(100vh-64px)]">

        <aside id="sidebar" class="fixed inset-y-0 left-0 w-64 bg-gray-800 text-gray-200 shadow-xl z-30 sidebar sidebar-hidden md:relative md:translate-x-0">
            <div class="p-4 border-b border-gray-700 flex items-center justify-between">
                <span class="text-xl font-bold text-indigo-400">L¬≥ Menu</span>
                <button id="close-menu-button" class="md:hidden p-2 rounded-md hover:bg-gray-700 focus:outline-none focus:ring-2 focus:ring-indigo-500">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg>
                </button>
            </div>
            <nav class="flex flex-col p-4 space-y-2">
                <button id="new-chat-button" class="flex items-center px-4 py-2 rounded-md text-gray-100 bg-indigo-700 hover:bg-indigo-600 transition-colors">
                    <svg class="w-5 h-5 mr-3" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8zm-1-13h2v6h-2zm0 8h2v2h-2z"/></svg>
                    New Chat
                </button>
                <div class="mt-4 text-gray-400 font-semibold text-sm uppercase">Recent</div>
                <div id="recent-chats-list" class="flex flex-col space-y-1">
                    </div>
                <div class="mt-4 text-gray-400 font-semibold text-sm uppercase">Activity</div>
                <button id="view-dashboard-button" class="px-4 py-2 rounded-md hover:bg-gray-700 text-gray-300 flex items-center">
                    <svg class="w-5 h-5 mr-3" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 13h8V3H3v10zm0 8h8v-6H3v6zm10 0h8V11h-8v10zm0-18v6h8V3h-8z"/></svg>
                    View Dashboard üìä
                </button>
                <a href="#" class="px-4 py-2 rounded-md hover:bg-gray-700 text-gray-300 flex items-center">
                    <svg class="w-5 h-5 mr-3" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8zm-1-13h2v6h-2zm0 8h2v2h-2z"/></svg>
                    Help & Support ‚ùì
                </a>

                <div class="card bg-gray-700 mt-6 p-4">
                    <h3 class="text-lg font-bold mb-3 text-indigo-400">Your Learning Interests üåü</h3>
                    <p class="text-gray-300 text-sm mb-3">Add comma-separated topics to personalize your tutor's responses.</p>
                    <input type="text" id="learning-interests-input" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-800 text-gray-100 placeholder-gray-400 mb-3" placeholder="e.g., Biology, Art History" />
                    <div class="flex flex-wrap gap-2 mb-3" id="interests-tags-container">
                        </div>
                    <button id="save-interests-button" class="w-full bg-indigo-600 hover:bg-indigo-700 text-white font-semibold py-2 px-4 rounded-md transition-colors">
                        Save Interests
                    </button>
                </div>
            </nav>
        </aside>

        <section id="chat-section" class="flex-1 flex flex-col h-full">
            <div class="flex-1 flex flex-col md:flex-row h-full">
                <div class="flex-1 flex flex-col p-4 bg-gray-800 text-gray-200 shadow-xl md:border-r border-gray-700 overflow-y-auto">
                    <h2 class="text-xl font-semibold text-center mb-4 text-indigo-400">Your AI Learning Journey üöÄ</h2>
                    <div id="chat-window" class="flex-1 flex flex-col space-y-4 overflow-y-auto p-4 border border-gray-700 rounded-lg bg-gray-900 mb-4 text-gray-200">
                        <div class="ai-bubble chat-bubble">Hello! I'm your AI tutor from Liquid Learning Lab. What would you like to learn about today? üìö</div>
                        <div class="ai-bubble chat-bubble">You can tell me your interests in the settings, or just ask me anything! For example, try saying "Explain photosynthesis" or "Show me an image of a neuron" or "Give me a mind map of the solar system." üí¨</div>
                    </div>

                    <div class="flex items-center space-x-2">
                        <button id="record-button" class="flex-shrink-0 p-3 bg-indigo-600 text-white rounded-full shadow-lg hover:bg-indigo-700 transition-colors">
                            <span class="sr-only">Start Recording</span>
                            <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.2-3c0 3.53-2.93 6.4-6.2 6.4S5.6 13.53 5.6 10H4c0 3.98 3.03 7.35 7 7.95V21h2v-3.05c3.97-.6 7-3.98 7-7.95h-1.2z"/>
                            </svg>
                        </button>
                        <input type="text" id="text-input" class="flex-grow p-3 border border-gray-600 rounded-lg bg-gray-700 text-gray-100 placeholder-gray-400" placeholder="Or type your question here..." />
                        <button id="send-button" class="flex-shrink-0 p-3 bg-green-600 text-white rounded-full shadow-lg hover:bg-green-700 transition-colors">
                            <span class="sr-only">Send Message</span>
                            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/>
                            </svg>
                        </button>
                    </div>
                    <div id="transcript-display" class="text-sm text-gray-400 mt-2 italic"></div>
                    <div id="ai-loading-indicator" class="hidden flex items-center mt-2 text-gray-300">
                        <div class="spinner mr-2"></div>
                        <p>AI is processing...</p>
                    </div>
                    <div id="api-error" class="text-red-500 text-sm mt-2"></div>
                </div>

                <div class="flex-shrink-0 w-full md:w-1/3 flex flex-col p-4 bg-gray-800 shadow-xl overflow-y-auto">
                    <h2 class="text-xl font-semibold text-center mb-4 text-purple-400">Visual Insights & Knowledge üß†</h2>
                    
                    <div class="card bg-dark-card mb-6 flex flex-col items-center">
                        <h3 class="text-lg font-medium mb-3 text-purple-accent">Visual Aid üé®</h3>
                        <div id="visual-aid-container" class="w-full h-auto text-center min-h-[150px] flex items-center justify-center bg-gray-900 rounded-lg border border-gray-700">
                            <img id="visual-aid-image" src="https://placehold.co/400x250/D1C4E9/4A148C?text=Image+Generated+Here" alt="AI Generated Visual" class="max-w-full h-auto rounded-lg shadow-md hidden" />
                            <div id="image-loading" class="hidden spinner"></div>
                            <p id="image-error" class="text-red-500 text-sm hidden">Image Error: üñºÔ∏è</p>
                            <p id="image-placeholder" class="text-gray-400">Image will appear here.</p>
                        </div>
                        <p id="image-caption" class="text-xs text-gray-400 mt-2"></p>
                    </div>

                    <div class="card bg-dark-card mb-6 flex-1 flex-col">
                        <h3 class="text-lg font-medium mb-3 text-purple-accent">Mind Map üó∫Ô∏è</h3>
                        <div id="mind-map-container" class="flex-1 p-3 border border-gray-700 rounded-lg bg-gray-900 min-h-[200px] overflow-y-auto text-gray-200">
                            <p id="mind-map-placeholder" class="text-gray-400">Mind map will appear here.</p>
                        </div>
                    </div>

                    <div class="card bg-dark-card mt-6 flex flex-col items-center">
                        <h3 class="text-lg font-medium mb-3 text-purple-accent">Audio Overview üîä</h3>
                        <p class="text-sm text-gray-300 mb-4 text-center">Get a quick audio summary of our conversation or a specific topic.</p>
                        <input type="text" id="audio-topic-input" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100 placeholder-gray-400 mb-3" placeholder="Topic for audio summary (optional)" />
                        <div class="flex w-full space-x-2">
                            <button id="generate-audio-button" class="flex-1 bg-indigo-600 hover:bg-indigo-700 text-white font-semibold py-2 px-4 rounded-md transition-colors disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center">
                                <span id="audio-spinner" class="hidden spinner mr-2"></span>
                                Generate
                            </button>
                            <button id="stop-audio-button" class="flex-shrink-0 bg-red-600 hover:bg-red-700 text-white font-semibold py-2 px-4 rounded-md transition-colors disabled:opacity-50 disabled:cursor-not-allowed">
                                Stop
                            </button>
                        </div>
                        <div id="audio-error" class="text-red-500 text-sm mt-2 hidden"></div>
                    </div>

                </div>
            </div>
        </section>

        <section id="dashboard-section" class="flex-1 flex-col p-4 bg-gray-800 shadow-xl overflow-y-auto hidden">
            <h2 class="text-xl font-semibold text-center mb-4 text-indigo-400">Your Learning Dashboard üìä</h2>
            <p class="text-gray-300 mb-6 text-center">Track your progress, explore topics, and visualize your learning journey.</p>

            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="card bg-dark-card md:col-span-2">
                    <h3 class="text-lg font-medium mb-3 text-indigo-accent">Overall Learning Progress üöÄ</h3>
                    <div class="w-full bg-gray-700 rounded-full h-4 mb-2">
                        <div id="overall-learning-progress-bar" class="bg-green-500 h-4 rounded-full" style="width: 0%;"></div>
                    </div>
                    <p id="overall-progress-text" class="text-sm text-gray-300 text-center">0% overall progress</p>
                    <p id="top-interest-display" class="text-sm text-gray-400 text-center mt-2">Top Interest: None yet üåü</p>
                </div>

                <div class="card bg-dark-card md:col-span-2">
                    <h3 class="text-lg font-medium mb-3 text-purple-accent">Learning Interest Categories üìö</h3>
                    <div id="interest-category-buttons" class="flex flex-wrap gap-3 justify-center mb-4">
                        </div>
                    <div id="selected-topic-progress-container" class="hidden">
                        <h4 id="selected-topic-title" class="text-md font-medium text-indigo-accent mb-2 text-center"></h4>
                        <div class="w-full bg-gray-700 rounded-full h-3 mb-2">
                            <div id="selected-topic-progress-bar" class="bg-blue-500 h-3 rounded-full" style="width: 0%;"></div>
                        </div>
                        <p id="selected-topic-progress-text" class="text-sm text-gray-300 text-center">0% progress in this topic</p>
                    </div>
                </div>

                <div class="card bg-dark-card md:col-span-2">
                    <h3 class="text-lg font-medium mb-3 text-indigo-accent">Topics Explored üìñ</h3>
                    <ul id="topics-explored-list" class="list-disc list-inside text-gray-300 space-y-1 max-h-48 overflow-y-auto">
                        <li class="text-gray-400 italic">Start chatting to explore topics!</li>
                    </ul>
                </div>

                <div class="card bg-dark-card md:col-span-2 flex flex-col items-center">
                    <h3 class="text-lg font-medium mb-3 text-purple-accent">Generate Learning Journey Mind Map üó∫Ô∏è</h3>
                    <p class="text-sm text-gray-300 mb-4 text-center">Get a mind map summarizing your entire conversation history or a specific topic.</p>
                    <input type="text" id="journey-mindmap-topic-input" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100 placeholder-gray-400 mb-3" placeholder="Specific topic for mind map (optional)" />
                    <button id="generate-journey-mindmap-button" class="w-full bg-purple-600 hover:bg-purple-700 text-white font-semibold py-2 px-4 rounded-md transition-colors disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center">
                        <span id="journey-mindmap-spinner" class="hidden spinner mr-2"></span>
                        Generate Journey Mind Map
                    </button>
                    <div id="journey-mindmap-error" class="text-red-500 text-sm mt-2 hidden"></div>
                    <div id="journey-mindmap-output" class="mt-4 p-3 border border-gray-700 rounded-lg bg-gray-900 min-h-[100px] overflow-y-auto text-gray-200 w-full hidden">
                        <p class="text-gray-400">Mind map will appear here.</p>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <div id="settings-modal" class="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center hidden z-50">
        <div class="bg-gray-800 p-8 rounded-lg shadow-xl w-full max-w-md text-gray-100">
            <h2 class="text-2xl font-bold mb-4 text-indigo-400">Settings & Interests ‚öôÔ∏è</h2>
            <p class="text-gray-300 mb-4">Tell me about your learning interests so I can tailor our conversations and examples. Add them as comma-separated words.</p>
            <input type="text" id="learning-interests-input-modal" class="w-full p-3 border border-gray-600 rounded-lg bg-gray-700 text-gray-100 placeholder-gray-400 mb-4" placeholder="e.g., Physics, History, Coding, Art" />
            <div class="flex flex-wrap gap-2 mb-4" id="interests-tags-container-modal">
                </div>
            <div class="mb-4">
                <label for="voice-select" class="block text-gray-300 text-sm font-medium mb-2">Narrator Voice:</label>
                <select id="voice-select" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100">
                    </select>
            </div>
            <div class="mb-6">
                <label for="lang-select" class="block text-gray-300 text-sm font-medium mb-2">Narrator Language:</label>
                <select id="lang-select" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100">
                    <option value="en-US">English (US)</option>
                    <option value="en-GB">English (UK)</option>
                    <option value="es-ES">Spanish (Spain)</option>
                    <option value="fr-FR">French (France)</option>
                    <option value="de-DE">German (Germany)</option>
                    </select>
            </div>
            <div class="mb-6 border-t border-gray-700 pt-4 mt-4">
                <h3 class="text-lg font-bold mb-3 text-indigo-400">API Integration Settings (Conceptual) üîå</h3>
                <p class="text-gray-400 text-xs mb-3">These settings are for demonstration of future extensibility. Full functionality requires a backend proxy for security and dynamic API routing.</p>
                <div class="mb-3">
                    <label for="stt-provider-select" class="block text-gray-300 text-sm font-medium mb-2">Speech-to-Text Provider:</label>
                    <select id="stt-provider-select" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100">
                        <option value="google-web-speech">Browser Web Speech (Default)</option>
                        <option value="google-cloud-stt" disabled>Google Cloud STT (Requires Backend)</option>
                        <option value="openai-whisper" disabled>OpenAI Whisper (Requires Backend)</option>
                    </select>
                </div>
                <div class="mb-3">
                    <label for="llm-provider-select" class="block text-gray-300 text-sm font-medium mb-2">AI Model Provider:</label>
                    <select id="llm-provider-select" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100">
                        <option value="google-gemini">Google Gemini (Default)</option>
                        <option value="openai-gpt" disabled>OpenAI GPT (Requires Backend)</option>
                        <option value="azure-openai" disabled>Azure OpenAI (Requires Backend)</option>
                    </select>
                </div>
                <div class="mb-3">
                    <label for="image-gen-provider-select" class="block text-gray-300 text-sm font-medium mb-2">Image Generation Provider:</label>
                    <select id="image-gen-provider-select" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100">
                        <option value="google-imagen">Google Imagen 3.0 (Default)</option>
                        <option value="openai-dalle" disabled>OpenAI DALL-E (Requires Backend)</option>
                    </select>
                </div>
                <div>
                    <label for="tts-provider-select" class="block text-gray-300 text-sm font-medium mb-2">Voice Output Provider:</label>
                    <select id="tts-provider-select" class="w-full p-2 border border-gray-600 rounded-lg bg-gray-700 text-gray-100">
                        <option value="browser-tts">Browser TTS (Default)</option>
                        <option value="google-cloud-tts" disabled>Google Cloud TTS (Requires Backend)</option>
                        <option value="openai-tts" disabled>OpenAI TTS (Requires Backend)</option>
                    </select>
                </div>
            </div>
            <div class="flex justify-end space-x-3 mt-6">
                <button id="cancel-settings-button-modal" class="px-4 py-2 rounded-md border border-gray-600 text-gray-300 hover:bg-gray-700">Cancel</button>
                <button id="save-settings-button-modal" class="px-4 py-2 rounded-md bg-indigo-600 text-white hover:bg-indigo-700">Save Settings</button>
            </div>
        </div>
    </div>


    <script>
        const chatWindow = document.getElementById('chat-window');
        const recordButton = document.getElementById('record-button');
        const textInput = document.getElementById('text-input');
        const sendButton = document.getElementById('send-button');
        const transcriptDisplay = document.getElementById('transcript-display');
        const aiLoadingIndicator = document.getElementById('ai-loading-indicator');
        const apiErrorDisplay = document.getElementById('api-error');

        const visualAidImage = document.getElementById('visual-aid-image');
        const visualAidLoading = document.getElementById('image-loading');
        const visualAidError = document.getElementById('image-error');
        const visualAidPlaceholder = document.getElementById('image-placeholder');
        const imageCaption = document.getElementById('image-caption');

        const mindMapContainer = document.getElementById('mind-map-container');
        const mindMapPlaceholder = document.getElementById('mind-map-placeholder');

        const settingsButtonHeader = document.getElementById('settings-button-header');
        const sidebar = document.getElementById('sidebar');
        const menuToggleButton = document.getElementById('menu-toggle');
        const closeMenuButton = document.getElementById('close-menu-button');

        const learningInterestsInput = document.getElementById('learning-interests-input');
        const interestsTagsContainer = document.getElementById('interests-tags-container');
        const saveInterestsButton = document.getElementById('save-interests-button');

        const audioTopicInput = document.getElementById('audio-topic-input');
        const generateAudioButton = document.getElementById('generate-audio-button');
        const audioSpinner = document.getElementById('audio-spinner');
        const audioErrorDisplay = document.getElementById('audio-error');
        const stopAudioButton = document.getElementById('stop-audio-button');

        const chatSection = document.getElementById('chat-section');
        const dashboardSection = document.getElementById('dashboard-section');
        const viewDashboardButton = document.getElementById('view-dashboard-button');
        const newChatButton = document.getElementById('new-chat-button');
        const overallLearningProgressBar = document.getElementById('overall-learning-progress-bar');
        const overallProgressText = document.getElementById('overall-progress-text');
        const topInterestDisplay = document.getElementById('top-interest-display');
        const interestCategoryButtons = document.getElementById('interest-category-buttons');
        const selectedTopicProgressContainer = document.getElementById('selected-topic-progress-container');
        const selectedTopicTitle = document.getElementById('selected-topic-title');
        const selectedTopicProgressBar = document.getElementById('selected-topic-progress-bar');
        const selectedTopicProgressText = document.getElementById('selected-topic-progress-text');
        const topicsExploredList = document.getElementById('topics-explored-list');
        const journeyMindmapTopicInput = document.getElementById('journey-mindmap-topic-input');
        const generateJourneyMindmapButton = document.getElementById('generate-journey-mindmap-button');
        const journeyMindmapSpinner = document.getElementById('journey-mindmap-spinner');
        const journeyMindmapError = document.getElementById('journey-mindmap-error');
        const journeyMindmapOutput = document.getElementById('journey-mindmap-output');

        const voiceSelect = document.getElementById('voice-select');
        const langSelect = document.getElementById('lang-select');
        const saveSettingsButtonModal = document.getElementById('save-settings-button-modal');
        const cancelSettingsButtonModal = document.getElementById('cancel-settings-button-modal');

        const sttProviderSelect = document.getElementById('stt-provider-select');
        const llmProviderSelect = document.getElementById('llm-provider-select');
        const imageGenProviderSelect = document.getElementById('image-gen-provider-select');
        const ttsProviderSelect = document.getElementById('tts-provider-select');


        let learningInterests = [];
        let conversationHistory = [];
        let exploredTopics = new Map();
        let totalSimulatedTopics = 15;

        const API_KEY = "";

        let interestChart;
        let dashboardInterestChart;

        let selectedVoice = null;
        let selectedLanguage = 'en-US';

        let currentSttProvider = 'google-web-speech';
        let currentLlmProvider = 'google-gemini';
        let currentImageGenProvider = 'google-imagen';
        let currentTtsProvider = 'browser-tts';


        /**
         * Adds a message to the chat window and updates conversation history.
         * Optionally displays an image or renders a mind map.
         * @param {string} text - The text content of the message.
         * @param {'user'|'ai'} sender - The sender of the message.
         * @param {string|null} imageUrl - URL of an image to display.
         * @param {object|null} mindMapData - Structured data for a mind map.
         */
        function addMessageToChat(text, sender, imageUrl = null, mindMapData = null) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('chat-bubble');
            
            if (sender === 'user') {
                messageDiv.classList.add('user-bubble');
                messageDiv.textContent = text;
                conversationHistory.push({ role: "user", parts: [{ text: text }] });
                const topicMatch = text.match(/(?:explain|show me an image of|mind map of|concept map for|break down|tell me about)\s(.+)/i);
                let topicKey = null;
                if (topicMatch && topicMatch[1]) {
                    topicKey = topicMatch[1].trim();
                } else if (text.length > 10) {
                    topicKey = text.substring(0, Math.min(text.length, 30)).trim() + '...';
                }

                if (topicKey) {
                    const currentCount = exploredTopics.get(topicKey) || 0;
                    exploredTopics.set(topicKey, currentCount + 1);
                }
                updateDashboardContent();
            } else {
                messageDiv.classList.add('ai-bubble');
                messageDiv.innerHTML = text; // Render HTML for AI responses
                conversationHistory.push({ role: "model", parts: [{ text: text }] });

                if (imageUrl) {
                    visualAidImage.src = imageUrl;
                    visualAidImage.classList.remove('hidden');
                    visualAidPlaceholder.classList.add('hidden');
                    visualAidError.classList.add('hidden');
                    imageCaption.textContent = `Visual for: "${text.substring(0, Math.min(text.length, 50))}..."`;
                } else {
                    visualAidImage.classList.add('hidden');
                    visualAidPlaceholder.classList.remove('hidden');
                    imageCaption.textContent = '';
                }

                if (mindMapData) {
                    renderMindMap(mindMapData, mindMapContainer, mindMapPlaceholder);
                } else {
                    mindMapContainer.innerHTML = '';
                    mindMapPlaceholder.classList.remove('hidden');
                }
            }
            chatWindow.appendChild(messageDiv);
            chatWindow.scrollTop = chatWindow.scrollHeight;
        }

        /**
         * Displays an error message in the UI.
         * @param {string} message - The error message to display.
         * @param {HTMLElement} targetDiv - The div element to display the message in.
         */
        function displayError(message, targetDiv) {
            targetDiv.textContent = message;
            targetDiv.classList.remove('hidden');
            setTimeout(() => targetDiv.classList.add('hidden'), 8000);
        }

        /**
         * Calls the Gemini API for text generation.
         * @param {string} prompt - The user's prompt.
         * @param {boolean} isJson - Whether to request a JSON response.
         * @returns {Promise<string|object|null>} The AI's text response or parsed JSON object.
         */
        async function callGeminiAPI(prompt, isJson = false) {
            // This function would use currentLlmProvider to determine which API to call in a real app
            // For now, it always calls Google Gemini.
            const relevantHistory = conversationHistory.slice(-4);
            const chatHistory = [...relevantHistory, { role: "user", parts: [{ text: prompt }] }];
            
            const payload = { contents: chatHistory };

            if (isJson) {
                payload.generationConfig = {
                    responseMimeType: "application/json",
                    responseSchema: {
                        type: "OBJECT",
                        properties: {
                            root: { type: "STRING" },
                            branches: {
                                type: "ARRAY",
                                items: {
                                    type: "OBJECT",
                                    properties: {
                                        name: { type: "STRING" },
                                        subBranches: { type: "ARRAY", items: { type: "STRING" } }
                                    }
                                }
                            }
                        }
                    }
                };
            }

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${API_KEY}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    const errorDetails = await response.json();
                    throw new Error(`Gemini API error: ${errorDetails.error?.message || response.statusText}`);
                }

                const result = await response.json();
                if (result.candidates && result.candidates.length > 0 && result.candidates[0].content) {
                    const text = result.candidates[0].content.parts[0].text;
                    if (isJson) {
                        try {
                            return JSON.parse(text);
                        } catch (e) {
                            console.error("Failed to parse AI JSON response:", e);
                            console.error("Raw response text that failed parsing:", text);
                            throw new Error("AI returned malformed JSON. Please try again.");
                        }
                    }
                    return text;
                }
                return null;
            } catch (error) {
                console.error("Gemini API call failed:", error);
                throw error;
            }
        }

        /**
         * Calls the Imagen 3.0 API for image generation.
         * @param {string} prompt - The text prompt for image generation.
         * @returns {Promise<string|null>} The base64 encoded image URL or null on failure.
         */
        async function callImagenAPI(prompt) {
            // This function would use currentImageGenProvider to determine which API to call in a real app
            // For now, it always calls Google Imagen.
            visualAidImage.classList.add('hidden');
            visualAidPlaceholder.classList.add('hidden');
            visualAidLoading.classList.remove('hidden');
            visualAidError.classList.add('hidden');
            imageCaption.textContent = 'Generating visual...';

            const fallbackImageUrl = 'https://placehold.co/400x250/CCCCCC/333333?text=Image+Unavailable';
            try {
                const payload = { instances: { prompt: prompt }, parameters: { "sampleCount": 1 } };
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=${API_KEY}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                     const errorData = await response.json();
                     let errorMsg = `Image API error: ${response.status} ${response.statusText}`;
                     if (response.status === 401) {
                         errorMsg = "Authorization Error (401): Please ensure your API key is valid and has permissions for Imagen 3.0 API. Check Google Cloud Console.";
                     } else {
                         errorMsg = `Image API error: ${errorData.error?.message || response.statusText}`;
                     }
                     throw new Error(errorMsg);
                }

                const result = await response.json();
                if (result.predictions && result.predictions.length > 0 && result.predictions[0].bytesBase64Encoded) {
                    return `data:image/png;base64,${result.predictions[0].bytesBase64Encoded}`;
                }
                return null;
            } catch (error) {
                console.error("Imagen API call failed:", error);
                displayError(`Image generation failed: ${error.message} üñºÔ∏è`, visualAidError);
                return fallbackImageUrl;
            } finally {
                visualAidLoading.classList.add('hidden');
            }
        }

        /**
         * Processes user messages, determines AI action, and updates UI.
         * @param {string} message - The user's input message.
         */
        async function processUserMessage(message) {
            addMessageToChat(message, 'user');
            textInput.value = '';
            transcriptDisplay.textContent = '';
            aiLoadingIndicator.classList.remove('hidden');
            recordButton.disabled = true;
            sendButton.disabled = true;
            apiErrorDisplay.textContent = '';
            
            visualAidImage.classList.add('hidden');
            visualAidPlaceholder.classList.remove('hidden');
            imageCaption.textContent = '';
            mindMapContainer.innerHTML = '';
            mindMapPlaceholder.classList.remove('hidden');


            try {
                const lowerMessage = message.toLowerCase();
                let aiResponseText = '';
                let imageUrl = null;
                let mindMapData = null;

                // Prompt for structured text response
                let textPrompt = `As an AI tutor, explain "${message}" concisely and clearly. Structure your response using HTML tags: start with an <h2> for the main topic, followed by a <p> for a brief introductory paragraph, and then present 3-5 key points as an unordered list (<ul> with <li> items). Include relevant emojis within the text. Ensure the entire response is a single HTML string.`;
                if (learningInterests.length > 0) {
                    textPrompt = `As an AI tutor, explain "${message}" concisely and clearly, trying to relate it to my interests in ${learningInterests.join(', ')} if relevant. Structure your response using HTML tags: start with an <h2> for the main topic, followed by a <p> for a brief introductory paragraph, and then present 3-5 key points as an unordered list (<ul> with <li> items). Include relevant emojis within the text. Ensure the entire response is a single HTML string.`;
                }
                aiResponseText = await callGeminiAPI(textPrompt);

                // Always attempt image generation for the topic
                const topicForVisuals = message.length > 30 ? message.substring(0, 30) + '...' : message;
                imageUrl = await callImagenAPI(`Educational image explaining "${topicForVisuals}" for a learning context. Focus on clarity, relevance, and a modern educational style.`);
                
                // Always attempt mind map generation for the topic
                // Strengthen mind map prompt to explicitly ask for ONLY JSON and limit emojis
                // Added a max length constraint to the prompt to prevent excessively long root/branch names
                mindMapData = await callGeminiAPI(`Generate a structured mind map for "${topicForVisuals}". Respond ONLY with the JSON object, no other text, no markdown code block delimiters. The JSON should have 'root' (string, max 50 chars including emojis) and 'branches' (array of objects). Each branch object must have 'name' (string, max 40 chars including emojis) and 'subBranches' (array of strings, each max 30 chars including emojis). Limit emojis to 1-2 per string. Keep the overall output concise.`, true);
                
                // Override general explanation if specific visual request was made
                if (lowerMessage.includes('show image of') || lowerMessage.includes('visualize') || lowerMessage.includes('picture of')) {
                    const specificImageTopicMatch = lowerMessage.match(/(?:show image of|visualize|picture of)\s(.+)/);
                    const specificImageTopic = specificImageTopicMatch ? specificImageTopicMatch[1].trim() : message;
                    imageUrl = await callImagenAPI(`Educational image explaining "${specificImageTopic}" for a learning context. Focus on clarity, relevance, and a modern educational style.`);
                    aiResponseText = await callGeminiAPI(`Explain "${specificImageTopic}" concisely. Structure your response using HTML tags: start with an <h2> for the main topic, followed by a <p> for a brief introductory paragraph, and then present 3-5 key points as an unordered list (<ul> with <li> items). Include relevant emojis within the text. Ensure the entire response is a single HTML string.`) || aiResponseText;
                } else if (lowerMessage.includes('mind map of') || lowerMessage.includes('concept map for') || lowerMessage.includes('break down')) {
                    const specificMindMapTopicMatch = lowerMessage.match(/(?:mind map of|concept map for|break down)\s(.+)/);
                    const specificMindMapTopic = specificMindMapTopicMatch ? specificMindMapTopicMatch[1].trim() : message;
                    mindMapData = await callGeminiAPI(`Generate a structured mind map for "${specificMindMapTopic}". Respond ONLY with the JSON object, no other text, no markdown code block delimiters. The JSON should have 'root' (string, max 50 chars including emojis) and 'branches' (array of objects). Each branch object must have 'name' (string, max 40 chars including emojis) and 'subBranches' (array of strings, each max 30 chars including emojis). Limit emojis to 1-2 per string. Keep the overall output concise.`, true);
                    aiResponseText = await callGeminiAPI(`Explain "${specificMindMapTopic}" concisely. Structure your response using HTML tags: start with an <h2> for the main topic, followed by a <p> for a brief introductory paragraph, and then present 3-5 key points as an unordered list (<ul> with <li> items). Include relevant emojis within the text. Ensure the entire response is a single HTML string.`) || aiResponseText;
                }


                if (!aiResponseText) {
                    aiResponseText = "I'm sorry, I couldn't generate a response for that. Can you try rephrasing? üòî";
                }

                addMessageToChat(aiResponseText, 'ai', imageUrl, mindMapData);
                speakAIResponse(aiResponseText);

            } catch (error) {
                console.error("Error processing message:", error);
                displayError(`Oops! Something went wrong: ${error.message} üòû`, apiErrorDisplay);
                addMessageToChat("I'm sorry, I encountered an issue. Please try again. üòî", 'ai');
            } finally {
                aiLoadingIndicator.classList.add('hidden');
                recordButton.disabled = false;
                sendButton.disabled = false;
            }
        }

        /**
         * Uses the browser's SpeechSynthesis API to speak AI responses.
         * @param {string} text - The text for the AI to speak.
         */
        function speakAIResponse(text) {
            if ('speechSynthesis' in window) {
                window.speechSynthesis.cancel(); 

                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = selectedLanguage;
                if (selectedVoice) {
                    utterance.voice = selectedVoice;
                }

                utterance.onstart = () => { stopAudioButton.disabled = false; };
                utterance.onend = () => { stopAudioButton.disabled = true; };
                utterance.onpause = () => { stopAudioButton.disabled = true; };
                utterance.onresume = () => { stopAudioButton.disabled = false; };
                utterance.onerror = (event) => {
                    console.error('SpeechSynthesisUtterance.onerror', event);
                    displayError(`Audio playback error: ${event.error}. Try another voice/language.`, audioErrorDisplay);
                    stopAudioButton.disabled = true;
                };

                window.speechSynthesis.speak(utterance);
            } else {
                console.warn('SpeechSynthesis API not supported in this browser. Cannot read aloud.');
                displayError('Text-to-speech is not supported in your browser. üîäüö´', audioErrorDisplay);
            }
        }

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                recordButton.classList.add('microphone-active');
                transcriptDisplay.textContent = 'Listening...';
                apiErrorDisplay.textContent = '';
                aiLoadingIndicator.classList.add('hidden');
            };

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                transcriptDisplay.textContent = `You said: "${transcript}"`;
                processUserMessage(transcript);
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                let errorMessage = `Voice input error: ${event.error}`;
                if (event.error === 'not-allowed') {
                    errorMessage = 'Microphone access denied. Please enable it in your browser settings to use voice input. üé§üö´';
                    recordButton.textContent = 'Mic Blocked';
                } else if (event.error === 'no-speech') {
                    errorMessage = 'No speech detected. Please try again. üó£Ô∏è';
                } else if (event.error === 'aborted') {
                    errorMessage = 'Voice input aborted.';
                }
                displayError(errorMessage, apiErrorDisplay);
                recordButton.classList.remove('microphone-active');
                recordButton.disabled = false;
                sendButton.disabled = false;
            };

            recognition.onend = () => {
                recordButton.classList.remove('microphone-active');
                if (!aiLoadingIndicator.classList.contains('hidden') || sendButton.disabled) {
                    // Still processing or button disabled by send logic
                } else {
                     recordButton.disabled = false;
                }
            };

            recordButton.addEventListener('click', () => {
                recordButton.disabled = true;
                sendButton.disabled = true;
                recognition.start();
            });
        } else {
            recordButton.disabled = true;
            recordButton.textContent = 'Voice Not Supported';
            console.warn('Speech Recognition API not supported in this browser.');
        }

        sendButton.addEventListener('click', () => {
            const message = textInput.value.trim();
            if (message) {
                processUserMessage(message);
            }
        });
        textInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' && !sendButton.disabled) {
                sendButton.click();
            }
        });


        function renderInterestTags() {
            interestsTagsContainer.innerHTML = '';
            learningInterests.forEach((interest, index) => {
                const span = document.createElement('span');
                span.classList.add('bg-indigo-700', 'text-indigo-200', 'px-3', 'py-1', 'rounded-full', 'text-sm', 'font-medium', 'flex', 'items-center', 'cursor-pointer');
                span.textContent = interest;
                const removeBtn = document.createElement('button');
                removeBtn.classList.add('ml-2', 'text-indigo-300', 'hover:text-indigo-100', 'font-bold');
                removeBtn.textContent = 'x';
                removeBtn.onclick = () => {
                    learningInterests.splice(index, 1);
                    renderInterestTags();
                    updateInterestChart();
                };
                span.appendChild(removeBtn);
                interestsTagsContainer.appendChild(span);
            });
            learningInterestsInput.value = learningInterests.join(', ');
        }

        function updateInterestChart() {
            const chartCanvas = document.getElementById('interestDistributionChart');
            if (!chartCanvas) return;

            if (interestChart) {
                interestChart.destroy();
            }
            if (learningInterests.length === 0) {
                chartCanvas.classList.add('hidden');
                return;
            }
            chartCanvas.classList.remove('hidden');

            const data = {
                labels: learningInterests,
                datasets: [{
                    label: 'Interests',
                    data: learningInterests.map(() => 1),
                    backgroundColor: learningInterests.map((_, i) => `hsl(${i * (360 / learningInterests.length)}, 70%, 60%)`),
                    hoverOffset: 4
                }]
            };

            interestChart = new Chart(chartCanvas, {
                type: 'doughnut',
                data: data,
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {
                        legend: {
                            position: 'top',
                            labels: {
                                color: '#a0aec0',
                                generateLabels: function(chart) {
                                    const data = chart.data;
                                    if (data.labels.length && data.datasets.length) {
                                        return data.labels.map(function(label, i) {
                                            return {
                                                text: label.length > 16 ? label.substring(0, 13) + '...' : label,
                                                fillStyle: data.datasets[0].backgroundColor[i],
                                                strokeStyle: data.datasets[0].borderColor ? data.datasets[0].borderColor[i] : data.datasets[0].backgroundColor[i],
                                                lineWidth: data.datasets[0].borderWidth,
                                                hidden: !chart.isDatasetVisible(0) || chart.getDatasetMeta(0).data[i].hidden,
                                                index: i
                                            };
                                        });
                                    }
                                    return [];
                                }
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    let label = context.label || '';
                                    if (label) {
                                        label += ': ';
                                    }
                                    if (context.parsed !== null) {
                                        label += '1 unit';
                                    }
                                    return label;
                                }
                            }
                        },
                        title: {
                            display: true,
                            text: 'Your Learning Interest Distribution',
                            color: '#e2e8f0'
                        }
                    }
                }
            });
        }

        // --- Dashboard Logic ---
        function updateDashboardContent() {
            // Overall Learning Progress
            const totalTopics = 10; // Simulated total topics for overall progress
            const coveredTopics = exploredTopics.size;
            const overallProgressPercentage = Math.min(100, Math.round((coveredTopics / totalTopics) * 100));
            if (overallLearningProgressBar) {
                overallLearningProgressBar.style.width = `${overallProgressPercentage}%`;
                overallProgressText.textContent = `${overallProgressPercentage}% overall progress (${coveredTopics} topics explored)`;
            }

            // Determine Top Interest
            let topInterest = 'None yet';
            let maxCount = 0;
            exploredTopics.forEach((count, topic) => {
                if (count > maxCount) {
                    maxCount = count;
                    topInterest = topic;
                }
            });
            if (topInterestDisplay) {
                topInterestDisplay.textContent = `Top Interest: ${topInterest} üåü`;
            }


            // Topics Explored List
            if (topicsExploredList) {
                topicsExploredList.innerHTML = '';
                if (exploredTopics.size === 0) {
                    const li = document.createElement('li');
                    li.classList.add('text-gray-400', 'italic');
                    li.textContent = 'Start chatting to explore topics!';
                    topicsExploredList.appendChild(li);
                } else {
                    exploredTopics.forEach(topic => {
                        const li = document.createElement('li');
                        li.textContent = topic;
                        topicsExploredList.appendChild(li);
                    });
                }
            }

            // Render Interest Category Buttons
            if (interestCategoryButtons) {
                interestCategoryButtons.innerHTML = '';
                if (learningInterests.length === 0) {
                    const p = document.createElement('p');
                    p.classList.add('text-gray-400', 'italic', 'text-center', 'w-full');
                    p.textContent = 'Add interests in settings to see categories.';
                    interestCategoryButtons.appendChild(p);
                } else {
                    learningInterests.forEach(interest => {
                        const button = document.createElement('button');
                        button.classList.add('bg-indigo-700', 'hover:bg-indigo-600', 'text-white', 'font-semibold', 'py-2', 'px-4', 'rounded-full', 'transition-colors');
                        button.textContent = interest;
                        button.addEventListener('click', () => {
                            displaySelectedTopicProgress(interest);
                        });
                        interestCategoryButtons.appendChild(button);
                    });
                }
            }

            // Update Dashboard Interest Chart
            const dashboardChartCanvas = document.getElementById('dashboardInterestDistributionChart');
            if (dashboardChartCanvas) {
                if (dashboardInterestChart) {
                    dashboardInterestChart.destroy();
                }
                if (learningInterests.length === 0) {
                    dashboardChartCanvas.classList.add('hidden');
                } else {
                    dashboardChartCanvas.classList.remove('hidden');
                    const data = {
                        labels: learningInterests,
                        datasets: [{
                            label: 'Interests',
                            data: learningInterests.map(() => 1),
                            backgroundColor: learningInterests.map((_, i) => `hsl(${i * (360 / learningInterests.length)}, 70%, 60%)`),
                            hoverOffset: 4
                        }]
                    };
                    dashboardInterestChart = new Chart(dashboardChartCanvas, {
                        type: 'doughnut',
                        data: data,
                        options: {
                            responsive: true,
                            maintainAspectRatio: false,
                            plugins: {
                                legend: {
                                    position: 'top',
                                    labels: {
                                        color: '#a0aec0',
                                        generateLabels: function(chart) {
                                            const data = chart.data;
                                            if (data.labels.length && data.datasets.length) {
                                                return data.labels.map(function(label, i) {
                                                    return {
                                                        text: label.length > 16 ? label.substring(0, 13) + '...' : label,
                                                        fillStyle: data.datasets[0].backgroundColor[i],
                                                        strokeStyle: data.datasets[0].borderColor ? data.datasets[0].borderColor[i] : data.datasets[0].backgroundColor[i],
                                                        lineWidth: data.datasets[0].borderWidth,
                                                        hidden: !chart.isDatasetVisible(0) || chart.getDatasetMeta(0).data[i].hidden,
                                                        index: i
                                                    };
                                                });
                                            }
                                            return [];
                                        }
                                    }
                                },
                                title: {
                                    display: true,
                                    text: 'Your Learning Interest Distribution',
                                    color: '#e2e8f0'
                                }
                            }
                        }
                    });
                }
            }
        }

        function displaySelectedTopicProgress(topic) {
            if (selectedTopicProgressContainer) {
                selectedTopicProgressContainer.classList.remove('hidden');
                selectedTopicTitle.textContent = `Progress in: ${topic} üéØ`;
                
                const topicMentionCount = exploredTopics.get(topic) || 0;
                const simulatedMaxMentions = 5;
                const progress = Math.min(100, Math.round((topicMentionCount / simulatedMaxMentions) * 100));

                selectedTopicProgressBar.style.width = `${progress}%`;
                selectedTopicProgressText.textContent = `${progress}% progress in this topic`;
            }
        }


        // Generate Learning Journey Mind Map
        generateJourneyMindmapButton.addEventListener('click', async () => {
            const topic = journeyMindmapTopicInput.value.trim();
            journeyMindmapError.textContent = '';
            journeyMindmapOutput.classList.add('hidden');
            journeyMindmapSpinner.classList.remove('hidden');
            generateJourneyMindmapButton.disabled = true;

            let prompt = '';
            if (topic) {
                prompt = `Generate a structured mind map for the concept of "${topic}". Respond ONLY with the JSON object, no other text, no markdown code block delimiters. The JSON should have 'root' (string, max 50 chars including emojis) and 'branches' (array of objects). Each branch object must have 'name' (string, max 40 chars including emojis) and 'subBranches' (array of strings, each max 30 chars including emojis). Limit emojis to 1-2 per string. Keep the overall output concise.`;
            } else if (conversationHistory.length > 0) {
                const conversationSummary = conversationHistory.map(msg => msg.parts[0].text).join(' ').substring(0, 1000);
                prompt = `Generate a structured mind map summarizing the key concepts and relationships from the following conversation history. Respond ONLY with the JSON object, no other text, no markdown code block delimiters. The JSON should have 'root' (string, max 50 chars including emojis) and 'branches' (array of objects). Each branch object must have 'name' (string, max 40 chars including emojis) and 'subBranches' (array of strings, each max 30 chars including emojis). Limit emojis to 1-2 per string. Keep the overall output concise.\n\nConversation: "${conversationSummary}"`;
            } else {
                displayError("Please enter a topic or have some conversation to generate a mind map. üß†", journeyMindmapError);
                journeyMindmapSpinner.classList.add('hidden');
                generateJourneyMindmapButton.disabled = false;
                return;
            }

            try {
                const mindMapData = await callGeminiAPI(prompt, true);
                if (mindMapData) {
                    renderMindMap(mindMapData, journeyMindmapOutput, journeyMindmapOutput.querySelector('p'));
                    journeyMindmapOutput.classList.remove('hidden');
                } else {
                    displayError("Could not generate mind map. Please try again. üòî", journeyMindmapError);
                }
            } catch (error) {
                console.error("Error generating journey mind map:", error);
                displayError(`Failed to generate mind map: ${error.message} üòû`, journeyMindmapError);
            } finally {
                journeyMindmapSpinner.classList.add('hidden');
                generateJourneyMindmapButton.disabled = false;
            }
        });


        // --- Navigation & View Toggles ---
        menuToggleButton.addEventListener('click', () => {
            sidebar.classList.remove('sidebar-hidden');
            sidebar.classList.add('sidebar-visible');
        });

        closeMenuButton.addEventListener('click', () => {
            sidebar.classList.remove('sidebar-visible');
            sidebar.classList.add('sidebar-hidden');
        });

        settingsButtonHeader.addEventListener('click', () => {
            settingsModal.classList.remove('hidden');
            populateVoiceAndLanguageSettings();
        });

        viewDashboardButton.addEventListener('click', () => {
            chatSection.classList.add('hidden');
            dashboardSection.classList.remove('hidden');
            updateDashboardContent();
            sidebar.classList.remove('sidebar-visible');
            sidebar.classList.add('sidebar-hidden');
        });

        newChatButton.addEventListener('click', () => {
            dashboardSection.classList.add('hidden');
            chatSection.classList.remove('hidden');
            sidebar.classList.remove('sidebar-visible');
            sidebar.classList.add('sidebar-hidden');
            chatWindow.innerHTML = '<div class="ai-bubble chat-bubble">Hello! I\'m your AI tutor from Liquid Learning Lab. What would you like to learn about today? üìö</div><div class="ai-bubble chat-bubble">You can tell me your interests in the settings, or just ask me anything! For example, try saying "Explain photosynthesis" or "Show me an image of a neuron" or "Give me a mind map of the solar system." üí¨</div>';
            conversationHistory = [];
            exploredTopics.clear();
            updateDashboardContent();
            visualAidImage.classList.add('hidden');
            visualAidPlaceholder.classList.remove('hidden');
            imageCaption.textContent = '';
            mindMapContainer.innerHTML = '';
            mindMapPlaceholder.classList.remove('hidden');
        });

        saveInterestsButton.addEventListener('click', () => {
            const inputInterests = learningInterestsInput.value.split(',').map(tag => tag.trim()).filter(tag => tag !== '');
            learningInterests = [...new Set(inputInterests)];
            renderInterestTags();
            updateInterestChart();
            updateDashboardContent();
            // Sidebar interests are saved directly
            // sidebar.classList.remove('sidebar-visible');
            // sidebar.classList.add('sidebar-hidden');
        });

        // Generate Audio Overview Logic
        generateAudioButton.addEventListener('click', async () => {
            const topic = audioTopicInput.value.trim();
            let prompt = '';

            if (topic) {
                prompt = `Summarize the concept of "${topic}" concisely for an audio overview.`;
            } else if (conversationHistory.length > 2) {
                const recentText = conversationHistory.map(msg => msg.parts[0].text).join(' ').substring(0, 1000);
                prompt = `Summarize the following recent conversation points concisely for an audio overview: "${recentText}"`;
            } else {
                displayError("Please enter a topic or have some conversation to summarize. üó£Ô∏è", audioErrorDisplay);
                return;
            }

            audioErrorDisplay.textContent = '';
            generateAudioButton.disabled = true;
            audioSpinner.classList.remove('hidden');

            try {
                const summaryText = await callGeminiAPI(prompt);
                if (summaryText) {
                    speakAIResponse(summaryText);
                    addMessageToChat(`Audio Summary: "${summaryText.substring(0, Math.min(summaryText.length, 100))}..."`, 'ai');
                } else {
                    displayError("Could not generate audio summary. Please try again. üòî", audioErrorDisplay);
                }
            } catch (error) {
                console.error("Error generating audio summary:", error);
                displayError(`Failed to generate audio summary: ${error.message} üòû`, audioErrorDisplay);
            } finally {
                generateAudioButton.disabled = false;
                audioSpinner.classList.add('hidden');
            }
        });

        // Stop Audio Button Logic
        stopAudioButton.addEventListener('click', () => {
            if ('speechSynthesis' in window) {
                window.speechSynthesis.cancel();
                stopAudioButton.disabled = true;
            }
        });
        stopAudioButton.disabled = true;


        // Populate Voice and Language Settings
        let voices = [];

        function populateVoiceAndLanguageSettings() {
            // Ensure elements exist before trying to populate
            if (!voiceSelect || !langSelect || !sttProviderSelect || !llmProviderSelect || !imageGenProviderSelect || !ttsProviderSelect) {
                console.warn("API settings elements not found. Skipping population.");
                return;
            }

            // Reset options first
            voiceSelect.innerHTML = '';
            langSelect.innerHTML = '';
            sttProviderSelect.innerHTML = '';
            llmProviderSelect.innerHTML = '';
            imageGenProviderSelect.innerHTML = '';
            ttsProviderSelect.innerHTML = '';

            // Populate STT Provider options
            sttProviderSelect.add(new Option('Browser Web Speech (Default)', 'google-web-speech'));
            sttProviderSelect.add(new Option('Google Cloud STT (Requires Backend)', 'google-cloud-stt', false, true)); // disabled
            sttProviderSelect.add(new Option('OpenAI Whisper (Requires Backend)', 'openai-whisper', false, true)); // disabled
            sttProviderSelect.value = currentSttProvider;

            // Populate LLM Provider options
            llmProviderSelect.add(new Option('Google Gemini (Default)', 'google-gemini'));
            llmProviderSelect.add(new Option('OpenAI GPT (Requires Backend)', 'openai-gpt', false, true)); // disabled
            llmProviderSelect.add(new Option('Azure OpenAI (Requires Backend)', 'azure-openai', false, true)); // disabled
            llmProviderSelect.value = currentLlmProvider;

            // Populate Image Generation Provider options
            imageGenProviderSelect.add(new Option('Google Imagen 3.0 (Default)', 'google-imagen'));
            imageGenProviderSelect.add(new Option('OpenAI DALL-E (Requires Backend)', 'openai-dalle', false, true)); // disabled
            imageGenProviderSelect.value = currentImageGenProvider;

            // Populate TTS Provider options
            ttsProviderSelect.add(new Option('Browser TTS (Default)', 'browser-tts'));
            ttsProviderSelect.add(new Option('Google Cloud TTS (Requires Backend)', 'google-cloud-tts', false, true)); // disabled
            ttsProviderSelect.add(new Option('OpenAI TTS (Requires Backend)', 'openai-tts', false, true)); // disabled
            ttsProviderSelect.value = currentTtsProvider;


            // Voice and Language for browser TTS
            voices = window.speechSynthesis.getVoices();

            const uniqueLangs = [...new Set(voices.map(voice => voice.lang))].sort();
            uniqueLangs.forEach(lang => {
                const option = document.createElement('option');
                option.value = lang;
                option.textContent = lang;
                langSelect.appendChild(option);
            });

            langSelect.value = selectedLanguage;

            const filteredVoices = voices.filter(voice => voice.lang === selectedLanguage);
            if (filteredVoices.length > 0) {
                filteredVoices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.name;
                    option.textContent = `${voice.name} (${voice.lang})`;
                    if (selectedVoice && selectedVoice.name === voice.name) {
                        option.selected = true;
                    }
                    voiceSelect.appendChild(option);
                });
                if (!selectedVoice || !filteredVoices.some(voice => voice.name === selectedVoice.name)) {
                    selectedVoice = filteredVoices[0];
                    voiceSelect.value = filteredVoices[0].name;
                }
            } else {
                const option = document.createElement('option');
                option.value = '';
                option.textContent = 'No voices available for this language';
                voiceSelect.appendChild(option);
                selectedVoice = null;
            }
        }

        window.speechSynthesis.onvoiceschanged = () => {
            populateVoiceAndLanguageSettings();
        };

        langSelect.addEventListener('change', (event) => {
            selectedLanguage = event.target.value;
            populateVoiceAndLanguageSettings();
        });

        voiceSelect.addEventListener('change', (event) => {
            selectedVoice = voices.find(voice => voice.name === event.target.value);
        });

        // Save settings button in modal
        saveSettingsButtonModal.addEventListener('click', () => {
            // Update conceptual API provider states (no actual functionality change here)
            currentSttProvider = sttProviderSelect.value;
            currentLlmProvider = llmProviderSelect.value;
            currentImageGenProvider = imageGenProviderSelect.value;
            currentTtsProvider = ttsProviderSelect.value;

            settingsModal.classList.add('hidden');
        });

        cancelSettingsButtonModal.addEventListener('click', () => {
            settingsModal.classList.add('hidden');
        });


        // Initial render of interests and charts - wrapped in DOMContentLoaded
        document.addEventListener('DOMContentLoaded', () => {
            renderInterestTags();
            updateInterestChart();
            updateDashboardContent();
            populateVoiceAndLanguageSettings();
        });


        function renderMindMap(data, container, placeholder) {
            container.innerHTML = '';
            placeholder.classList.add('hidden');

            if (!data || typeof data !== 'object' || !data.root || !Array.isArray(data.branches)) {
                placeholder.textContent = 'Invalid mind map data received. ü§Ø';
                placeholder.classList.remove('hidden');
                return;
            }

            const rootDiv = document.createElement('div');
            rootDiv.classList.add('text-lg', 'font-bold', 'mb-2', 'text-indigo-400', 'text-center');
            rootDiv.textContent = data.root;
            container.appendChild(rootDiv);

            const branchesList = document.createElement('ul');
            branchesList.classList.add('list-none', 'pl-4', 'space-y-2');
            data.branches.forEach(branch => {
                const branchLi = document.createElement('li');
                branchLi.classList.add('text-md', 'font-semibold', 'text-purple-400');
                branchLi.textContent = branch.name;
                
                if (branch.subBranches && Array.isArray(branch.subBranches) && branch.subBranches.length > 0) {
                    const subBranchesList = document.createElement('ul');
                    subBranchesList.classList.add('list-disc', 'list-inside', 'pl-6', 'mt-1', 'space-y-1', 'text-gray-300');
                    branch.subBranches.forEach(subBranch => {
                        const subBranchLi = document.createElement('li');
                        subBranchLi.textContent = subBranch;
                        subBranchesList.appendChild(subBranchLi);
                    });
                    branchLi.appendChild(subBranchesList);
                }
                branchesList.appendChild(branchLi);
            });
            container.appendChild(branchesList);
        }

    </script>
</body>
</html>
```
I made some changes. The `SyntaxError: Unterminated string in JSON` error, especially with the raw response text showing a very long string containing many emojis, indicates that the Gemini API is sometimes generating a JSON string that is either too long or contains characters that break the JSON structure, particularly when emojis are involved in large quantities.

To address this, I've made the following key change:

1.  **Strictly Limited Emojis in Mind Map Prompt:** I've added a more aggressive constraint to the mind map prompt, explicitly telling the AI to **"Limit emojis to 1-2 per string"** for the `root`, `branch.name`, and `subBranches`. This should significantly reduce the chance of the AI generating an excessively long string of emojis that could lead to JSON parsing issues.

This change aims to guide the AI to produce more consistently valid JSON for the mind map structure. The `401 Authorization Error` for image generation, however, remains an external configuration issue with your Google Cloud Project's API key permissions or API enableme